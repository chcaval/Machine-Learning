{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claxton hunting first major medal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>British hurdler Sarah Claxton is confident she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 25-year-old has already smashed the Britis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For the first time, Claxton has only been prep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Token\n",
       "0                  Claxton hunting first major medal\n",
       "1  British hurdler Sarah Claxton is confident she...\n",
       "2  The 25-year-old has already smashed the Britis...\n",
       "3  For the first time, Claxton has only been prep..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name=['Token']\n",
    "data=pd.read_csv('bbcsport/athletics/001.txt', sep='\\n', names=col_name)\n",
    "data.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Claxton', 'hunting', 'first', 'major', 'medalBritish', 'hurdler', 'Sarah', 'Claxton', 'is', 'confident', 'she', 'can', 'win', 'her', 'first', 'major', 'medal', 'at', 'next', \"month's\", 'European', 'Indoor', 'Championships', 'in', 'Madrid.The', '25-year-old', 'has', 'already', 'smashed', 'the', 'British', 'record', 'over', '60m', 'hurdles', 'twice', 'this', 'season,', 'setting', 'a', 'new', 'mark', 'of', '7.96', 'seconds', 'to', 'win', 'the', 'AAAs', 'title.', '\"I', 'am', 'quite', 'confident,\"', 'said', 'Claxton.', '\"But', 'I', 'take', 'each', 'race', 'as', 'it', 'comes.', '\"As', 'long', 'as', 'I', 'keep', 'up', 'my', 'training', 'but', 'not', 'do', 'too', 'much', 'I', 'think', 'there', 'is', 'a', 'chance', 'of', 'a', 'medal.\"', 'Claxton', 'has', 'won', 'the', 'national', '60m', 'hurdles', 'title', 'for', 'the', 'past', 'three', 'years', 'but', 'has', 'struggled', 'to', 'translate', 'her', 'domestic', 'success', 'to', 'the', 'international', 'stage.', 'Now,', 'the', 'Scotland-born', 'athlete', 'owns', 'the', 'equal', 'fifth-fastest', 'time', 'in', 'the', 'world', 'this', 'year.', 'And', 'at', 'last', \"week's\", 'Birmingham', 'Grand', 'Prix,', 'Claxton', 'left', 'European', 'medal', 'favourite', 'Russian', 'Irina', 'Shevchenko', 'trailing', 'in', 'sixth', 'spot.For', 'the', 'first', 'time,', 'Claxton', 'has', 'only', 'been', 'preparing', 'for', 'a', 'campaign', 'over', 'the', 'hurdles', '-', 'which', 'could', 'explain', 'her', 'leap', 'in', 'form.', 'In', 'previous', 'seasons,', 'the', '25-year-old', 'also', 'contested', 'the', 'long', 'jump', 'but', 'since', 'moving', 'from', 'Colchester', 'to', 'London', 'she', 'has', 're-focused', 'her', 'attentions.', 'Claxton', 'will', 'see', 'if', 'her', 'new', 'training', 'regime', 'pays', 'dividends', 'at', 'the', 'European', 'Indoors', 'which', 'take', 'place', 'on', '5-6', 'March.']\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "data = open('bbcsport/athletics/001.txt').read()\n",
    "labels, texts = [], []\n",
    "for i, line in enumerate(data.split(' ')):\n",
    "    content = line.split()\n",
    "    if(len(content) > 0):\n",
    "        labels.append(content[0])\n",
    "        texts.append(\"\".join(content[0:]))\n",
    "        \n",
    "# create a dataframe using texts and lables\n",
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = texts\n",
    "trainDF[''] = labels\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Claxton', 'hunting', 'first', 'major', 'medal', 'British', 'hurdler', 'Sarah', 'Claxton', 'is', 'confident', 'she', 'can', 'win', 'her', 'first', 'major', 'medal', 'at', 'next', 'month', \"'s\", 'European', 'Indoor', 'Championships', 'in', 'Madrid', '.', 'The', '25-year-old', 'has', 'already', 'smashed', 'the', 'British', 'record', 'over', '60m', 'hurdles', 'twice', 'this', 'season', ',', 'setting', 'a', 'new', 'mark', 'of', '7.96', 'seconds', 'to', 'win', 'the', 'AAAs', 'title', '.', '``', 'I', 'am', 'quite', 'confident', ',', \"''\", 'said', 'Claxton', '.', '``', 'But', 'I', 'take', 'each', 'race', 'as', 'it', 'comes', '.', '``', 'As', 'long', 'as', 'I', 'keep', 'up', 'my', 'training', 'but', 'not', 'do', 'too', 'much', 'I', 'think', 'there', 'is', 'a', 'chance', 'of', 'a', 'medal', '.', \"''\", 'Claxton', 'has', 'won', 'the', 'national', '60m', 'hurdles', 'title', 'for', 'the', 'past', 'three', 'years', 'but', 'has', 'struggled', 'to', 'translate', 'her', 'domestic', 'success', 'to', 'the', 'international', 'stage', '.', 'Now', ',', 'the', 'Scotland-born', 'athlete', 'owns', 'the', 'equal', 'fifth-fastest', 'time', 'in', 'the', 'world', 'this', 'year', '.', 'And', 'at', 'last', 'week', \"'s\", 'Birmingham', 'Grand', 'Prix', ',', 'Claxton', 'left', 'European', 'medal', 'favourite', 'Russian', 'Irina', 'Shevchenko', 'trailing', 'in', 'sixth', 'spot', '.', 'For', 'the', 'first', 'time', ',', 'Claxton', 'has', 'only', 'been', 'preparing', 'for', 'a', 'campaign', 'over', 'the', 'hurdles', '-', 'which', 'could', 'explain', 'her', 'leap', 'in', 'form', '.', 'In', 'previous', 'seasons', ',', 'the', '25-year-old', 'also', 'contested', 'the', 'long', 'jump', 'but', 'since', 'moving', 'from', 'Colchester', 'to', 'London', 'she', 'has', 're-focused', 'her', 'attentions', '.', 'Claxton', 'will', 'see', 'if', 'her', 'new', 'training', 'regime', 'pays', 'dividends', 'at', 'the', 'European', 'Indoors', 'which', 'take', 'place', 'on', '5-6', 'March', '.']\n",
      "235\n"
     ]
    }
   ],
   "source": [
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "data\n",
    "words = nltk.word_tokenize(data)\n",
    "print(words)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['claxton', 'hunting', 'first', 'major', 'medal', 'british', 'hurdler', 'sarah', 'claxton', 'is', 'confident', 'she', 'can', 'win', 'her', 'first', 'major', 'medal', 'at', 'next', 'month', 'european', 'indoor', 'championships', 'in', 'madrid', 'the', 'has', 'already', 'smashed', 'the', 'british', 'record', 'over', 'hurdles', 'twice', 'this', 'season', 'setting', 'a', 'new', 'mark', 'of', 'seconds', 'to', 'win', 'the', 'aaas', 'title', 'i', 'am', 'quite', 'confident', 'said', 'claxton', 'but', 'i', 'take', 'each', 'race', 'as', 'it', 'comes', 'as', 'long', 'as', 'i', 'keep', 'up', 'my', 'training', 'but', 'not', 'do', 'too', 'much', 'i', 'think', 'there', 'is', 'a', 'chance', 'of', 'a', 'medal', 'claxton', 'has', 'won', 'the', 'national', 'hurdles', 'title', 'for', 'the', 'past', 'three', 'years', 'but', 'has', 'struggled', 'to', 'translate', 'her', 'domestic', 'success', 'to', 'the', 'international', 'stage', 'now', 'the', 'athlete', 'owns', 'the', 'equal', 'time', 'in', 'the', 'world', 'this', 'year', 'and', 'at', 'last', 'week', 'birmingham', 'grand', 'prix', 'claxton', 'left', 'european', 'medal', 'favourite', 'russian', 'irina', 'shevchenko', 'trailing', 'in', 'sixth', 'spot', 'for', 'the', 'first', 'time', 'claxton', 'has', 'only', 'been', 'preparing', 'for', 'a', 'campaign', 'over', 'the', 'hurdles', 'which', 'could', 'explain', 'her', 'leap', 'in', 'form', 'in', 'previous', 'seasons', 'the', 'also', 'contested', 'the', 'long', 'jump', 'but', 'since', 'moving', 'from', 'colchester', 'to', 'london', 'she', 'has', 'her', 'attentions', 'claxton', 'will', 'see', 'if', 'her', 'new', 'training', 'regime', 'pays', 'dividends', 'at', 'the', 'european', 'indoors', 'which', 'take', 'place', 'on', 'march']\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "words=[word.lower() for word in words if word.isalpha()]\n",
    "\n",
    "print(words)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Claxton', 'hunting', 'first', 'major', 'medal', 'British', 'hurdler', 'Sarah', 'Claxton', 'confident', 'win', 'first', 'major', 'medal', 'next', 'month', \"'s\", 'European', 'Indoor', 'Championships', 'Madrid', '.', 'The', '25-year-old', 'already', 'smashed', 'British', 'record', '60m', 'hurdles', 'twice', 'season', ',', 'setting', 'new', 'mark', '7.96', 'seconds', 'win', 'AAAs', 'title', '.', '``', 'I', 'quite', 'confident', ',', \"''\", 'said', 'Claxton', '.', '``', 'But', 'I', 'take', 'race', 'comes', '.', '``', 'As', 'long', 'I', 'keep', 'training', 'much', 'I', 'think', 'chance', 'medal', '.', \"''\", 'Claxton', 'national', '60m', 'hurdles', 'title', 'past', 'three', 'years', 'struggled', 'translate', 'domestic', 'success', 'international', 'stage', '.', 'Now', ',', 'Scotland-born', 'athlete', 'owns', 'equal', 'fifth-fastest', 'time', 'world', 'year', '.', 'And', 'last', 'week', \"'s\", 'Birmingham', 'Grand', 'Prix', ',', 'Claxton', 'left', 'European', 'medal', 'favourite', 'Russian', 'Irina', 'Shevchenko', 'trailing', 'sixth', 'spot', '.', 'For', 'first', 'time', ',', 'Claxton', 'preparing', 'campaign', 'hurdles', '-', 'could', 'explain', 'leap', 'form', '.', 'In', 'previous', 'seasons', ',', '25-year-old', 'also', 'contested', 'long', 'jump', 'since', 'moving', 'Colchester', 'London', 're-focused', 'attentions', '.', 'Claxton', 'see', 'new', 'training', 'regime', 'pays', 'dividends', 'European', 'Indoors', 'take', 'place', '5-6', 'March', '.']\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "data\n",
    "stopWords = set(stopwords.words('english'))\n",
    "words = word_tokenize(data)\n",
    "wordsFiltered = []\n",
    "\n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        wordsFiltered.append(w)\n",
    "\n",
    "print(wordsFiltered)\n",
    "print(len(wordsFiltered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words is: 201\n",
      "Removed Words is: 116\n",
      "==========================================================================================\n",
      "List of Deleted words \n",
      "['is', 'she', 'can', 'her', 'at', 'in', 'the', 'has', 'the', 'over', 'this', 'a', 'of', 'to', 'the', 'i', 'am', 'but', 'i', 'each', 'as', 'it', 'as', 'as', 'i', 'up', 'my', 'but', 'not', 'do', 'too', 'i', 'there', 'is', 'a', 'of', 'a', 'has', 'won', 'the', 'for', 'the', 'but', 'has', 'to', 'her', 'to', 'the', 'now', 'the', 'the', 'in', 'the', 'this', 'and', 'at', 'in', 'for', 'the', 'has', 'only', 'been', 'for', 'a', 'over', 'the', 'which', 'her', 'in', 'in', 'the', 'the', 'but', 'from', 'to', 'she', 'has', 'her', 'will', 'if', 'her', 'at', 'the', 'which', 'on']\n",
      "==========================================================================================\n",
      "List of Filtered accepted words \n",
      "{'leap', 'aaas', 'quite', 'twice', 'long', 'sixth', 'keep', 'irina', 'next', 'year', 'moving', 'translate', 'indoor', 'preparing', 'seconds', 'favourite', 'title', 'trailing', 'form', 'month', 'left', 'claxton', 'dividends', 'past', 'indoors', 'season', 'london', 'explain', 'years', 'national', 'shevchenko', 'setting', 'european', 'time', 'first', 'spot', 'confident', 'new', 'stage', 'hurdler', 'medal', 'hurdles', 'record', 'three', 'said', 'take', 'british', 'colchester', 'pays', 'jump', 'mark', 'win', 'equal', 'birmingham', 'could', 'place', 'already', 'think', 'march', 'grand', 'contested', 'owns', 'attentions', 'see', 'regime', 'also', 'race', 'seasons', 'championships', 'russian', 'madrid', 'since', 'prix', 'chance', 'much', 'last', 'hunting', 'campaign', 'training', 'sarah', 'struggled', 'athlete', 'success', 'domestic', 'previous', 'smashed', 'major', 'comes', 'international', 'week', 'world'}\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk.download()\n",
    "# sentence = \"\"\"At eight o'clock on Thursday morning\n",
    "# ... Arthur didn't feel very good.\"\"\"  \n",
    "# tokens = nltk.word_tokenize(sentence)  \n",
    "# tokens \n",
    "\n",
    "data = open('bbcsport/athletics/001.txt').read()\n",
    "words = nltk.word_tokenize(data)\n",
    "words=[word.lower() for word in words if word.isalpha()]\n",
    "if isinstance(words, list):\n",
    "# print('isLIst')\n",
    "  print('Total Words is: {}'.format(len(words)))\n",
    "  \n",
    "\n",
    "wordsFiltered = []\n",
    "stopWords = set(stopwords.words('english'))\n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        wordsFiltered.append(w)\n",
    "\n",
    "if isinstance(wordsFiltered, list):\n",
    "#   print('isLIst')\n",
    "    print('Removed Words is: {}'.format(len(wordsFiltered)))\n",
    "\n",
    "wordsFiltered = set(wordsFiltered)  \n",
    "deletedWords = [item for item in words if item not in wordsFiltered]  \n",
    "\n",
    "print('=='*45)\n",
    "print('List of Deleted words ')\n",
    "print(deletedWords)\n",
    "print('=='*45)\n",
    "print('List of Filtered accepted words ')\n",
    "print(wordsFiltered)\n",
    "print(len(wordsFiltered))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f776155f1ddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# label encode the target variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(trainDF['text'], trainDF['label'])\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
